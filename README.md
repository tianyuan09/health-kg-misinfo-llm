# health-kgraph-llm
A repository for a research project on health-related knowledge graph, LLM, and social media data

## Introduction


## Literature Review

<https://github.com/penghui-yang/awesome-data-poisoning-and-backdoor-attacks>

## Methods

### Data Source


### Tools

**Storage solution for knowledge graph used in **: <https://github.com/chroma-core/chroma> 


### Workflow 



## Results



## Discussion


## Reference

[Paperpile](https://paperpile.com/shared/LLM-data-poisoning-fyVnJRP5pR~6g31bFg~fBQg) 

* Yang, P. Awesome-Data-Poisoning-and-Backdoor-Attacks: A Curated List of Papers & Resources Linked to Data Poisoning, Backdoor Attacks and Defenses against Them (No Longer Maintained); Github;

* Alber, D.A.; Yang, Z.; Alyakin, A.; Yang, E.; Rai, S.; Valliani, A.A.; Zhang, J.; Rosenbaum, G.R.; Amend-Thomas, A.K.; Kurland, D.B.; et al. Medical Large Language Models Are Vulnerable to Data-Poisoning Attacks. Nat. Med. 2025, 1–9, doi:10.1038/s41591-024-03445-1.

* Mozaffari-Kermani, M.; Sur-Kolay, S.; Raghunathan, A.; Jha, N.K. Systematic Poisoning Attacks on and Defenses for Machine Learning in Healthcare. IEEE J. Biomed. Health Inform. 2015, 19, 1893–1905, doi:10.1109/JBHI.2014.2344095.

* Kurita, K.; Michel, P.; Neubig, G. Weight Poisoning Attacks on Pre-Trained Models. arXiv [cs.LG] 2020.
  

